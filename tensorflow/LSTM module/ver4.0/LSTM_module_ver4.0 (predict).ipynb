{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d11ad8",
   "metadata": {},
   "source": [
    "# Project: LSTM_module_predict\n",
    "\n",
    "학습된 모델로 음성파일 스팸 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b566d8f0",
   "metadata": {},
   "source": [
    "## 순서\n",
    "\n",
    "1. import: 필요한 모듈 import\n",
    "2. 파일 불러오기: 모델 학습에 사용된 객체, 변수 등 불러오기\n",
    "3. STT: 음성파일 STT변환\n",
    "4. 전처리: 텍스트 토큰화\n",
    "5. 예측: 스팸 탐지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485b67ae",
   "metadata": {},
   "source": [
    "## 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "185e7210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "import tensorflow as tf\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80f803c",
   "metadata": {},
   "source": [
    "## GPU 셋팅\n",
    "\n",
    "GPU 사용 시 활성화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c820b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589a0d96",
   "metadata": {},
   "source": [
    "## 파일 이름 선언\n",
    "\n",
    "필요 변수, 모델, 토큰 객체 등 파일 이름 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "144e4b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"LSTM_module_ver4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057ccd34",
   "metadata": {},
   "source": [
    "## 파일 불러오기\n",
    "\n",
    "tokenizer 객체 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1acd4be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name+'_tokenizer.pickle', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaa6d6",
   "metadata": {},
   "source": [
    "변수 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eb15800",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name+'_variable.json') as f:\n",
    "    var = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5f1263",
   "metadata": {},
   "source": [
    "불용어 단어 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51efd60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name+'_stopwords.json') as f:\n",
    "    stopwords = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d94f2e",
   "metadata": {},
   "source": [
    "불러온 변수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dfb760f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_data: 5\n",
      "max_len: 40\n",
      "trunc_type: post\n",
      "padding_type: post\n"
     ]
    }
   ],
   "source": [
    "min_data = var['min_data'] # 데이터 문자열 최소 길이\n",
    "max_len = var['max_len'] # 전체 데이터 셋 길이 설정 (메일의 최대 길이)\n",
    "trunc_type = var['trunc_type']\n",
    "padding_type = var['padding_type']\n",
    "\n",
    "print('min_data:',min_data)\n",
    "print('max_len:',max_len)\n",
    "print('trunc_type:',trunc_type)\n",
    "print('padding_type:',padding_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d7429e",
   "metadata": {},
   "source": [
    "## STT 변환\n",
    "\n",
    "음성파일 STT변환\n",
    "* `language`: 언어 설정\n",
    "* 약 80~100MB 용량 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b2096e89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여보세요 예 안녕하세요 서울중앙지검 유재민 수사관입니다 본인 되시나요 지금 본인 명의 도용 사건에 연루돼서 가지고 혹시 알고 계셨나요 혹시 본인 39세 남성의 황재연을 아시나요 경북 창원에 거주 중이고요 모르겠는데요 그럼 혹시 창원 방문하신 적 있으신가요 최근에 최근 6개월 이내 창원 방문하신 적 있으신가요가 본 적이 없는데요 그러시고 그럼 본인 최근에 모카 전화 통장분실 된 적 있으신가요 적 없어요 없으시고 지금 본인 김유정 씨께서 개인정보유출이 돼 가지고 이제 황재연 왜 13명 금융범죄 사기단이 은병 취득을 목적으로 대포통장을 개설해 가지고 지금 하기를 치고 있다가 이제 불법으로 검거를 하였습니다 저희가 아니 이제 개인정보 어떻게 일주일 제가 지갑을 잃어버린 적도 없고 그거는 아마 뭐 뭐 어쩌다가 뭐 무슨 홈페이지 같은데 들어가다가 유출된 걸 수도 있고 방법은 여러가지가 많거든요네 그래서 제 개인 정보가 이용되고 있다고요 그래 가지고 지금 본인 명의로 통장 개설 돼 가지고 지금 그런 생에 어디 은행 통장 2개월 된 거죠 신한은행입니다 신한은행 신한은행 통장 개설 없으시죠 없습니다 그러면 이게 저희가 지금 수사를 진행중이기 때문에 이제 본인께서 협조를 해 주셔야 되는데 혹시 통화 괜찮으신가요 아 지금 회사 긴 한데 내 통화할 수 있습니다네 본인 일단은 그러면 이제 녹취 수사를 진행할 예정인데 녹취 녹취 녹음을 해 가지고 아무래도 저희가 지금 이사 중이다 보니까 녹음을 해야 되는 상황이 나서 진행을 해야 될 거 같은데 본인 동의하시나요 이거보다 바쁜데 이용 되는 거 아닌가요 유정 씨 저 서울 중앙지검입니다 지금 경찰한테 이렇게 나오시면 안 되죠 아니 제가 어떡해 믿을 수가 있죠 경찰 경찰이니까 이제 서울 중앙지검 이겠죠 본인 지금 못 믿으시나요 못 믿으시면 저희가 소환장을 발고 해 줄 수도 있어요 직접 그러면 서울중앙지검 가지고 오셔야 됩니다네 그럼 내일 보내 주세요 제가 직접가 보겠습니다 아 그렇게 하신다고네 그렇게 할게요 예 알겠습니다네\n"
     ]
    }
   ],
   "source": [
    "r = sr.Recognizer()\n",
    "harvard = sr.AudioFile('spam1.flac') # 100MB 용량 제한\n",
    "with harvard as source:\n",
    "    audio = r.record(source)\n",
    "\n",
    "t = r.recognize_google(audio, language='ko-KR')\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9e214fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = \"요새 허리가 쑤시다 어떡하냐 며늘아\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e4d69d",
   "metadata": {},
   "source": [
    "## 전처리: 토큰화 및 불용어 처리\n",
    "\n",
    "Okt 객체 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ae2456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d95d586",
   "metadata": {},
   "source": [
    "토큰화 및 불용어 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2722f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preTreatment(data):\n",
    "    global stopwords\n",
    "    temp = okt.morphs(data, stem=True) # 토큰화\n",
    "    temp = [word for word in temp if not word in stopwords] # 불용어 처리\n",
    "    return temp\n",
    "\n",
    "data = preTreatment(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6dd9f6",
   "metadata": {},
   "source": [
    "## 모델 예측\n",
    "\n",
    "학습된 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a60c6af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 40, 16)            284736    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                20736     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 305,537\n",
      "Trainable params: 305,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(file_name+'.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c8e4bd",
   "metadata": {},
   "source": [
    "정수 인코딩 후 모델 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d7a21d08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "    data = tokenizer.texts_to_sequences([new_sentence])\n",
    "    pad_new = pad_sequences(data, maxlen = max_len, truncating = trunc_type, padding = padding_type)\n",
    "    score = float(model.predict(pad_new))\n",
    "    return score\n",
    "\n",
    "score_result = sentiment_predict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc7d465",
   "metadata": {},
   "source": [
    "## 예측 확률 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "057216ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.60% 확률로 스팸입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"{:.2f}% 확률로 스팸입니다.\\n\".format(score_result * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
