{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d11ad8",
   "metadata": {},
   "source": [
    "# Project: LSTM_module (predict)\n",
    "\n",
    "학습된 모델로 음성파일 스팸 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b566d8f0",
   "metadata": {},
   "source": [
    "## 순서\n",
    "\n",
    "1. import: 필요한 모듈 import\n",
    "2. 파일 불러오기: 모델 학습에 사용된 객체, 변수 등 불러오기\n",
    "3. STT: 음성파일 STT변환\n",
    "4. 전처리: 텍스트 토큰화\n",
    "5. 예측: 스팸 탐지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485b67ae",
   "metadata": {},
   "source": [
    "## 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "185e7210",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "import tensorflow as tf\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80f803c",
   "metadata": {},
   "source": [
    "## GPU 셋팅\n",
    "\n",
    "GPU 사용 시 활성화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "c820b092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589a0d96",
   "metadata": {},
   "source": [
    "## 파일 이름 선언\n",
    "\n",
    "필요 변수, 모델, 토큰 객체 등 파일 이름 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "144e4b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"LSTM_module_ver4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057ccd34",
   "metadata": {},
   "source": [
    "## 파일 불러오기\n",
    "\n",
    "tokenizer 객체 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1acd4be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name+'_tokenizer.pickle', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ccaa6d6",
   "metadata": {},
   "source": [
    "변수 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3eb15800",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name+'_variable.json') as f:\n",
    "    var = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5f1263",
   "metadata": {},
   "source": [
    "불용어 단어 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "51efd60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name+'_stopwords.json') as f:\n",
    "    stopwords = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d94f2e",
   "metadata": {},
   "source": [
    "불러온 변수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "0dfb760f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_data: 10\n",
      "data_length: 100\n",
      "max_len: 150\n",
      "trunc_type: post\n",
      "padding_type: post\n"
     ]
    }
   ],
   "source": [
    "min_data = var['min_data'] # 데이터 문자열 최소 길이\n",
    "data_length = var['data_length'] # 데이터 문자열 최대 길이\n",
    "split_list = var['split_list'] # 문장 단위로 분리하기 위한 글자 리스트\n",
    "max_len = var['max_len'] # 전체 데이터 셋 길이 설정 (메일의 최대 길이)\n",
    "trunc_type = var['trunc_type']\n",
    "padding_type = var['padding_type']\n",
    "\n",
    "print('min_data:',min_data)\n",
    "print('data_length:',data_length)\n",
    "print('max_len:',max_len)\n",
    "print('trunc_type:',trunc_type)\n",
    "print('padding_type:',padding_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d7429e",
   "metadata": {},
   "source": [
    "## STT 변환\n",
    "\n",
    "음성파일 STT변환\n",
    "* `language`: 언어 설정\n",
    "* 약 80~100MB 용량 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b2096e89",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r = sr.Recognizer()\n",
    "harvard = sr.AudioFile('spam2.flac') # 100MB 용량 제한\n",
    "with harvard as source:\n",
    "    audio = r.record(source)\n",
    "\n",
    "try:\n",
    "    t = r.recognize_google(audio, language='ko-KR')\n",
    "except:\n",
    "    t = '녹음 내용이 존재하지 않습니다.'\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e2fc4c",
   "metadata": {},
   "source": [
    "## 텍스트 데이터 분리\n",
    "\n",
    "**findIndex**: 문장이 끝나는 부분의 index값을 찾기위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3a395387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findIndex(data_list, split_list, start_index):\n",
    "    index_list = []\n",
    "    for i in split_list:\n",
    "        index = data_list.find(i, start_index)\n",
    "        index_list.append(index)\n",
    "        \n",
    "    index_list = [i for i in index_list if i not in [-1]]\n",
    "    if index_list == []:\n",
    "        return -1\n",
    "    \n",
    "    index = min(index_list)\n",
    "    \n",
    "    return index     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3972c6c",
   "metadata": {},
   "source": [
    "`data_length` 값 이후에 `split_list` 에 있는 문자가 나오면 자르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "305645d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = re.sub(\"네|[^가-힣 ]\", \"\", t) # 특수문자 제거\n",
    "index = findIndex(t, split_list, data_length)\n",
    "\n",
    "i = 0\n",
    "t_list = []\n",
    "while index != -1:\n",
    "    x = t[i:index+2]\n",
    "    t_list.append(x)\n",
    "\n",
    "    i = index+2\n",
    "    index = findIndex(t, split_list, i+data_length)\n",
    "else:\n",
    "    x = t[i:]\n",
    "    if len(x) > min_data:\n",
    "        t_list.append(x) # 텍스트 마지막 부분 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e4d69d",
   "metadata": {},
   "source": [
    "## 전처리: 토큰화 및 불용어 처리\n",
    "\n",
    "Okt 객체 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "4ae2456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d95d586",
   "metadata": {},
   "source": [
    "**preTreatment**: 토큰화 및 불용어 처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c2722f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preTreatment(data):\n",
    "    global stopwords\n",
    "    temp = okt.morphs(data, stem=True) # 토큰화\n",
    "    temp = [word for word in temp if not word in stopwords] # 불용어 처리\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b574fa60",
   "metadata": {},
   "source": [
    "**sentiment_predict**: 정수 인코딩 후 모델 예측 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "64f503f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "    data = tokenizer.texts_to_sequences([new_sentence])\n",
    "    pad_new = pad_sequences(data, maxlen = max_len, truncating = trunc_type, padding = padding_type)\n",
    "    score = float(model.predict(pad_new))\n",
    "    print(score)\n",
    "    print('----------------------')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6dd9f6",
   "metadata": {},
   "source": [
    "## 모델 예측\n",
    "\n",
    "학습된 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3a60c6af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 150)         750300    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               100400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 850,801\n",
      "Trainable params: 850,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(file_name+'.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c8e4bd",
   "metadata": {},
   "source": [
    "분리한 각 데이터 확률 예측 후 평균 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d7a21d08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여보세요 들리냐 하나 둘 셋 넷 잘들려 음 뭔 얘기를 할까 이게 스팸으로 인식을 할라나 모르겠 한다면 하는거고 뭐 상관없지 스팸 인식 안됐으면 좋겠\n",
      "0.0789751410484314\n",
      "----------------------\n"
     ]
    }
   ],
   "source": [
    "score_sum = 0.0\n",
    "for txt in t_list:\n",
    "    print(txt)\n",
    "    data = preTreatment(txt)\n",
    "    score_sum += sentiment_predict(data)\n",
    "    \n",
    "score_result = score_sum / len(t_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc7d465",
   "metadata": {},
   "source": [
    "## 예측 확률 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "057216ab",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.90% 확률로 스팸입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"{:.2f}% 확률로 스팸입니다.\\n\".format(score_result * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
