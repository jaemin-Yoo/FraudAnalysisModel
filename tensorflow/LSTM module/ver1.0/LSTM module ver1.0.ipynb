{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 총 개수: 8382\n",
      "테스트 데이터 총 개수: 2096\n",
      "훈련 데이터 스팸 개수 382\n",
      "테스트 데이터 스팸 개수 96\n",
      "훈련 데이터 일반 개수 8000\n",
      "테스트 데이터 일반 개수 2000\n",
      "--------------------------------\n",
      "스팸 데이터 예시\n",
      "\n",
      "\n",
      "\n",
      "여보세요 여보세요 네 수고하십니다. 저는 서울중앙지검에 이상민 계장입니다 예 다름이 아니라 본인 명의도용 사건 관련해서 연락을 드렸는데요. \n",
      "잠시 통화 가능하신가요.\n",
      "제 명의가 도용됐다고요 혹시. 서울 노원구 출신의 최장수라는 사람 알고 계십니까. \n",
      "모르는데요\n",
      "전직 \n",
      "--------------------------------\n",
      "일반 데이터 예시\n",
      "\n",
      "\n",
      "양치하고 올께 알겠오 다녀오세용 양치 끝 넌 근데 점심먹고 양ㅊ 하니? 아.. 오늘 안했네 양치해야겠다 밥 먹고 양치하고 커피 근데 커피 치아에 엄청 안좋대 그러니까 빨대로 목구멍에 바로 넘겨 입에 머금지 말고 응응 \n",
      "--------------------------------\n",
      "전처리 후 스팸 데이터 예시\n",
      "\n",
      "\n",
      "['여보세요', '여보세요', '네', '수고', '하다', '저', '는', '서', '울', '중앙', '지', '검', '에', '이상민', '계장', '이다', '예', '다르다', '아니다', '본인', '명의', '도용', '사건', '관련', '하다', '연락', '을', '드리다', '잠시', '통화', '가능하다', '제', '명의', '가', '도용', '돼다', '혹시', '서울', '노원구', '출신', '의', '최장수', '라는', '사람', '알', '고', '계시다', '모르다', '전직']\n",
      "--------------------------------\n",
      "전처리 후 일반 데이터 예시\n",
      "\n",
      "\n",
      "['양치', '하고', '오다', '알다', '다녀오다', '양치', '끝', '넌', '근데', '점심', '먹다', '양', 'ㅊ', '하니', '아', '..', '오늘', '안', '하다', '양치', '하다', '밥', '먹다', '양치', '하고', '커피', '근데', '커피', '치아', '에', '엄청', '안좋다', '그러니까', '빨대', '로', '목구멍', '에', '바로', '넘기다', '입', '에', '머', '금지', '말고', '응응']\n",
      "--------------------------------\n",
      "단어 집합(vocabulary)의 크기 : 24200\n",
      "등장 빈도가 2번 이하인 희귀 단어의 수: 15909\n",
      "단어 집합에서 희귀 단어의 비율: 65.7396694214876\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 4.603856447513201\n",
      "최대 길이 : 469\n",
      "평균 길이 : 49.66447917909557\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "object __array__ method not producing an array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-26ed7b8dc41d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n 테스트 정확도: %.4f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[0;32m   1064\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[0;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m         model=model)\n\u001b[0m\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m                **kwargs):\n\u001b[0;32m    264\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n\u001b[0;32m    267\u001b[0m         sample_weights, sample_weight_modes)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_process_tensorlike\u001b[1;34m(inputs)\u001b[0m\n\u001b[0;32m   1019\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m   \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_convert_numpy_and_scipy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_to_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 635\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_convert_numpy_and_scipy\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1014\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mscipy_sparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mscipy_sparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_scipy_sparse_to_sparse_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   1497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1498\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m   \u001b[1;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[1;31m# Unused.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    262\u001b[0m   \"\"\"\n\u001b[0;32m    263\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[1;32m--> 264\u001b[1;33m                         allow_broadcast=True)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    273\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tf.constant\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m   \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m   \u001b[1;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m   \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: object __array__ method not producing an array"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "temp_list = []\n",
    "train_X = []\n",
    "test_X = []\n",
    "train_y = []\n",
    "test_y = []\n",
    "train_cnt = 8000\n",
    "test_cnt = 2000\n",
    "\n",
    "# 피싱 대화 데이터 가져오기\n",
    "path = 'fraudDataset/spamData/'\n",
    "path1 = os.listdir(path)\n",
    "for a in path1:\n",
    "    path2 = path+a\n",
    "    with open(path2, 'r', encoding='utf-8') as f:\n",
    "        contents = f.read()\n",
    "        temp_list.append(contents)\n",
    "        \n",
    "for t in temp_list:\n",
    "    x = [t[i:i+150] for i in range(0, len(t), 150)] # 텍스트 파일 중 150 길이로 데이터 길이 제한\n",
    "    train_X.extend(x)\n",
    "\n",
    "# train, test Data 분리\n",
    "n_X = int(len(train_X) * 0.8)\n",
    "test_X = train_X[n_X:]\n",
    "train_X = train_X[:n_X]\n",
    "\n",
    "for y in range(len(train_X)):\n",
    "    train_y.append(1) # label 추가\n",
    "    \n",
    "for y in range(len(test_X)):\n",
    "    test_y.append(1)\n",
    "\n",
    "# 일상 대화 데이터 가져오기\n",
    "path = 'fraudDataset/hamData/'\n",
    "path1 = os.listdir(path)\n",
    "for a in path1:\n",
    "    path2 = os.listdir(path+a)\n",
    "    for b in path2:\n",
    "        path3 = path+a+'/'+b\n",
    "        with open(path3, 'r', encoding='utf-8') as f:\n",
    "            contents = f.read()\n",
    "            json_data = json.loads(contents)\n",
    "            data = ''\n",
    "            data = json_data['data']\n",
    "            for i in range(len(data)):                \n",
    "                sentence = ''\n",
    "                dialogue = data[i]['body']['dialogue']\n",
    "                for j in range(len(dialogue)):\n",
    "                    utterance = dialogue[j]['utterance']\n",
    "                    sentence += utterance+' '\n",
    "                \n",
    "                if a == 'Training':\n",
    "                    if train_y.count(0) == train_cnt:\n",
    "                        break\n",
    "                    train_X.append(sentence)\n",
    "                    train_y.append(0)\n",
    "                else:\n",
    "                    if test_y.count(0) == test_cnt:\n",
    "                        break\n",
    "                    test_X.append(sentence)\n",
    "                    test_y.append(0)\n",
    "\n",
    "print('훈련 데이터 총 개수:',len(train_X))\n",
    "print('테스트 데이터 총 개수:',len(test_X))\n",
    "print('훈련 데이터 스팸 개수',train_y.count(1))\n",
    "print('테스트 데이터 스팸 개수',test_y.count(1))\n",
    "print('훈련 데이터 일반 개수',train_y.count(0))\n",
    "print('테스트 데이터 일반 개수',test_y.count(0))\n",
    "print('--------------------------------')\n",
    "print('스팸 데이터 예시')\n",
    "print('\\n')\n",
    "print(train_X[0])\n",
    "print('--------------------------------')\n",
    "print('일반 데이터 예시')\n",
    "print('\\n')\n",
    "print(train_X[train_y.count(1)])\n",
    "print('--------------------------------')\n",
    "\n",
    "y_train = np.array(train_y)\n",
    "y_test = np.array(test_y)\n",
    "\n",
    "okt = Okt()\n",
    "stopwords = ['\\n','.','?',',','']\n",
    "\n",
    "X_train = []\n",
    "for sentence in train_X:\n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 처리\n",
    "    X_train.append(temp_X)\n",
    "\n",
    "X_test = []\n",
    "for sentence in test_X:\n",
    "    temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] # 불용어 처리\n",
    "    X_test.append(temp_X)\n",
    "    \n",
    "print('전처리 후 스팸 데이터 예시')\n",
    "print('\\n')\n",
    "print(X_train[0])\n",
    "print('--------------------------------')\n",
    "print('전처리 후 일반 데이터 예시')\n",
    "print('\\n')\n",
    "print(X_train[train_y.count(1)])\n",
    "print('--------------------------------')\n",
    "\n",
    "# 한글은 형태소 분석기 사용해야됨 KoNPLY\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "threshold = 3\n",
    "word_to_index = tokenizer.word_index\n",
    "total_cnt = len(word_to_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 토큰화된 각 단어 index를 json 형태로 저장\n",
    "import json\n",
    "json = json.dumps(word_to_index)\n",
    "with open(\"LSTM_module_ver1.0_wordIndex.json\", \"w\") as f:\n",
    "    f.write(json)\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "        \n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "\n",
    "#vocab_size = total_cnt - rare_cnt + 1\n",
    "vocab_size = total_cnt + 1 # predict Error 해결\n",
    "tokenizer = Tokenizer(vocab_size) \n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# 빈 샘플들을 제거\n",
    "drop_train = [index for index, sentence in enumerate(X_train) if len(sentence) < 1]\n",
    "X_train = np.delete(X_train, drop_train, axis=0)\n",
    "y_train = np.delete(y_train, drop_train, axis=0)\n",
    "print('최대 길이 :',max(len(l) for l in X_train))\n",
    "print('평균 길이 :',sum(map(len, X_train))/len(X_train))\n",
    "plt.hist([len(s) for s in X_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "max_len = 100 # 최대 길이\n",
    "X_train = pad_sequences(X_train, maxlen = max_len)\n",
    "X_test = pad_sequences(X_test, maxlen = max_len)\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, max_len))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('LSTM_module_ver1.0.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=60, validation_split=0.2)\n",
    "\n",
    "print(\"\\n 테스트 정확도: %.4f\" % (model.evaluate(X_test, y_test)[1]))\n",
    "\n",
    "epochs = range(1, len(history.history['acc']) + 1)\n",
    "plt.plot(epochs, history.history['loss'])\n",
    "plt.plot(epochs, history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
