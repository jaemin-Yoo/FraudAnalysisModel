{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb90ed08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 100)         2466000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,583,377\n",
      "Trainable params: 2,583,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "여보세요 여보세요네 혹시 그 당근마켓 그 신발 판매 안 하시는 일 보고 전화 드렸는데요 나이키 나이키 조던 그거 15만원에 올리셨던데 그 혹시 좀 할인 안 될까요 제가 아직 학생이라서 돈이 많이 없는데 된다고 적어 놨는데 내 돼요 얼마까지 가능하신가요 얼마까지 마세요 \n",
      "[89.92% 확률로 스팸입니다.]\n",
      "-------------------------------------------------------------------\n",
      "마음 같아서는 15만원까지 15만 원 15만 원 할인 15만 원 어디 사시죠 혹시 저는 거주중입니다 그러면 15만 원에 내일 하시죠 직거래 하시는 건가요 하면 될 거 같아요 근데 지금 요새 코로나 가지고 만나기가 좀 걸어 지는데 혹시 계좌 번호 알려 주시면 제가 보내 \n",
      "[99.87% 확률로 스팸입니다.]\n",
      "-------------------------------------------------------------------\n",
      "드리면 안 되나요 그러면 택배비 내셔야 될 텐데 괜찮으신가요 택배비는 본인이 부담하시는 거 아니에요 아니 저거는 직거래를 원하는데 분께서는 택배로 하시다고 하시니까 그쪽에서 내셔야 줘 아 그러면 경산으로 와 주실 건가요 아니요 저기 그 중간에 만나면 되지 않을까요 근데\n",
      "[81.94% 확률로 스팸입니다.]\n",
      "-------------------------------------------------------------------\n",
      " 약간 걱정 돼 가지고 무서운 분이 나오시면 또 이제 큰일 나니까 아니요 그 당근마켓에 구매다 인증 이런 것도 있는데 아 보니까 청도 되게 좋더라구요 가지고 내 걱정 안 하셔도 됩니다 그러면 어디서 만날까요 그러면 어디 어디까지 올 수 있으신가요 혹시 월드컵 경기 대구\n",
      "[42.53% 확률로 스팸입니다.]\n",
      "-------------------------------------------------------------------\n",
      "스타디움 아세요 들어오는 봤어요 거기까지 가면 될까요 여기 오시면 제가 가겠습니다 아 그러면 일단 알겠습니다 그럼 하시는 건가요 그럼 바로 직거래 할까요 오늘은 제가 약속이 있어 가지고 제가 고소를 당해 가지고 오늘 경찰청에 가야 되는데 그거는 안 될 거 같고 아마 내\n",
      "[98.37% 확률로 스팸입니다.]\n",
      "-------------------------------------------------------------------\n",
      "일 내일은 가능할 것 같습니다 그러면 직장인이라서 내일 퇴근하고 6시 7시쯤 되시나요 그때쯤 그러면 저녁도 같이 함께할까요 아까 무서워 농담입니다 그럼 뭐 내일 6시에 7시 반에 대구스타디움 앞에서 직거래 하도록 그렇게 알고 있겠습니다 예 알겠습니다 감사합니다\n",
      "[0.60% 확률로 스팸입니다.]\n",
      "-------------------------------------------------------------------\n",
      "68.87% 확률로 스팸입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "import json\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# wordInext 목록 받아오기\n",
    "with open('LSTM_module_ver2.0_wordIndex.json') as f:\n",
    "    word_index = json.load(f)\n",
    "    tokenizer.word_index = word_index\n",
    "    \n",
    "with open('LSTM_module_ver2.0_variable.json') as f:\n",
    "    var = json.load(f)\n",
    "    \n",
    "max_data = var['max_data'] # 데이터 문자열 최대 길이\n",
    "min_data = var['min_data'] # 데이터 문자열 최소 길이\n",
    "max_len = var['max_len'] # 전체 데이터 셋 길이 설정 (메일의 최대 길이)\n",
    "\n",
    "model = tf.keras.models.load_model('LSTM_module_ver2.0.h5')\n",
    "model.summary()\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "def preTreatment(data):\n",
    "    stopwords = ['\\n','.','?',',','']\n",
    "    temp = okt.morphs(data, stem=True) # 토큰화\n",
    "    temp = [word for word in temp if not word in stopwords] # 불용어 처리\n",
    "    return temp\n",
    "\n",
    "\n",
    "def sentiment_predict(new_sentence):\n",
    "    data = tokenizer.texts_to_sequences([new_sentence]) # 단어를 숫자값, 인덱스로 변환하여 저장\n",
    "    pad_new = pad_sequences(data, maxlen = max_len) # 모든 메일의 길이를 100로 설정 (빈 부분은 0으로 패딩)\n",
    "    score = float(model.predict(pad_new))\n",
    "    print(\"[{:.2f}% 확률로 스팸입니다.]\".format(score * 100))\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    return score\n",
    "        \n",
    "\n",
    "# 음성파일 STT 변환\n",
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "harvard = sr.AudioFile('ham2.flac') # 100MB 용량 제한\n",
    "with harvard as source:\n",
    "    audio = r.record(source)\n",
    "\n",
    "t = r.recognize_google(audio, language='ko-KR')\n",
    "\n",
    "temp_X = []\n",
    "x = [t[i:i+max_data] for i in range(0, len(t), max_data)] # 텍스트 파일 중 150 길이로 데이터 길이 제한\n",
    "\n",
    "for s in x:\n",
    "    if len(s) > min_data: # 길이가 50 이하인 데이터 삭제\n",
    "        temp_X.append(s)\n",
    "x = temp_X\n",
    "score_sum = 0.0\n",
    "for txt in x:\n",
    "    print(txt)\n",
    "    data = preTreatment(txt)\n",
    "    score_sum += sentiment_predict(data)\n",
    "score_result = score_sum / len(x)\n",
    "print(\"{:.2f}% 확률로 스팸입니다.\\n\".format(score_result * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
