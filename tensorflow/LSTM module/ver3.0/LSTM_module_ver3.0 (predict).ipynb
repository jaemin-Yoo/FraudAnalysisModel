{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb90ed08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 60)          624840    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               64400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 689,341\n",
      "Trainable params: 689,341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "여보세요네 여보세요네네 안녕하세요 서울중앙지검 유재민 수사관입니다 혹시 통화 괜찮으신가요 아 다름이 아니라 지금 김유종 씨 본인 되시죠 맞는데요 그 지금은 명의도용 사건이 연료가 돼 가지고 제가 전화를 드렸어요 혹시 김수빈이라고 아시나요 숨을 22살에 23살의 여성인데\n",
      "[99.98% 확률로 스팸입니다.]\n",
      "-------------------------------------------------------------------\n",
      " 전직 농협 직원이 없고요 혹시 아시나요 아니요 모르는데요 모르시나요 혹시 그러면 경북 포항에 방문한 적이 있으신가요 간 적은 있습니다 거기서 뭐 통장이나 뭐 카드나 잃어버리신 적 있으신가요 없으시고 지금 그 김수빈 일당들이 지금 금융범죄에 4길 아닌데 지금 금융 취득\n",
      "[99.97% 확률로 스팸입니다.]\n",
      "-------------------------------------------------------------------\n",
      "을 목적으로 현재 통장을 만들어 가지고 이제 그렇게 사기를 치고 다니고 있습니다 그래가지고 내 현재 김유정 씨 본인이 개인정보가 유출된 거 같은데 그래 가지고 이제 그렇게 되신 거예요 그래서 혹시 괜찮으시다면 이제 저희가 이제 도와드릴 방법을 이제 찾고 있는데 어떻게 \n",
      "[99.98% 확률로 스팸입니다.]\n",
      "-------------------------------------------------------------------\n",
      "지금 통화 괜찮으시죠 오늘 통화는 가능합니다 지금 녹취 수사를 진행할 예정인데 녹취 수사 2동 일을 하시나요 지금 녹취 수술을 해야 이제 사건 점수가 되기 때문에 내내 동의합니다네 그러면 이제 물어보는 말에 이제 대답을 해 주시면 되고요 지금부터 녹취 수사 시작하도록 \n",
      "[99.98% 확률로 스팸입니다.]\n",
      "-------------------------------------------------------------------\n",
      "하겠습니다 안녕하세요 저는 서울중앙지검 유재민 수사관입니다 김유정 씨 생일이 어떻게 되세요 30일입니다 3월 31일 오케이\n",
      "[40.45% 확률로 스팸입니다.]\n",
      "-------------------------------------------------------------------\n",
      "88.07% 확률로 스팸입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "file_name = \"LSTM_module_ver3.0\"\n",
    "\n",
    "# GPU 있는 경우 활성화\n",
    "# physical_devices = tf.config.list_physical_devices('GPU')\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n",
    "with open(file_name+'_tokenizer.pickle', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "    \n",
    "with open(file_name+'_stopwords.json') as f:\n",
    "    stopwords = json.load(f)\n",
    "\n",
    "with open(file_name+'_variable.json') as f:\n",
    "    var = json.load(f)\n",
    "\n",
    "max_data = var['max_data'] # 데이터 문자열 최대 길이\n",
    "min_data = var['min_data'] # 데이터 문자열 최소 길이\n",
    "max_len = var['max_len'] # 전체 데이터 셋 길이 설정 (메일의 최대 길이)\n",
    "\n",
    "model = tf.keras.models.load_model(file_name+'.h5')\n",
    "model.summary()\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "def preTreatment(data):\n",
    "    global stopwords\n",
    "    temp = okt.morphs(data, stem=True) # 토큰화\n",
    "    temp = [word for word in temp if not word in stopwords] # 불용어 처리\n",
    "    return temp\n",
    "\n",
    "\n",
    "def sentiment_predict(new_sentence):\n",
    "    data = tokenizer.texts_to_sequences([new_sentence]) # 단어를 숫자값, 인덱스로 변환하여 저장\n",
    "    pad_new = pad_sequences(data, maxlen = max_len) # 모든 메일의 길이를 100로 설정 (빈 부분은 0으로 패딩)\n",
    "    score = float(model.predict(pad_new))\n",
    "    print(\"[{:.2f}% 확률로 스팸입니다.]\".format(score * 100))\n",
    "    print(\"-------------------------------------------------------------------\")\n",
    "    return score\n",
    "        \n",
    "\n",
    "# 음성파일 STT 변환\n",
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "harvard = sr.AudioFile('spam2.flac') # 100MB 용량 제한\n",
    "with harvard as source:\n",
    "    audio = r.record(source)\n",
    "\n",
    "t = r.recognize_google(audio, language='ko-KR')\n",
    "\n",
    "temp_X = []\n",
    "x = [t[i:i+max_data] for i in range(0, len(t), max_data)] # 텍스트 파일 중 150 길이로 데이터 길이 제한\n",
    "for s in x:\n",
    "    if len(s) >= min_data: # 길이가 50 미만인 데이터 삭제\n",
    "        temp_X.append(s)\n",
    "x = temp_X\n",
    "score_sum = 0.0\n",
    "for txt in x:\n",
    "    print(txt)\n",
    "    data = preTreatment(txt)\n",
    "    score_sum += sentiment_predict(data)\n",
    "score_result = score_sum / len(x)\n",
    "print(\"{:.2f}% 확률로 스팸입니다.\\n\".format(score_result * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
