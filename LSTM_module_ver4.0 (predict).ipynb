{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: LSTM_module (predict)\n",
    "\n",
    "학습된 모델로 음성파일 스팸 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 순서\n",
    "\n",
    "1. import: 필요한 모듈 import\n",
    "2. 파일 불러오기: 모델 학습에 사용된 객체, 변수 등 불러오기\n",
    "3. STT: 음성파일 STT변환\n",
    "4. 전처리: 텍스트 토큰화\n",
    "5. 예측: 스팸 탐지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import pickle5 as pickle\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import speech_recognition as sr\n",
    "\n",
    "import tensorflow as tf\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU 셋팅\n",
    "\n",
    "GPU 사용 시 활성화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일 이름 선언\n",
    "\n",
    "필요 변수, 모델, 토큰 객체 등 파일 이름 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"LSTM_module_ver4.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토큰화 객체 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open(file_name+'_tokenizer.pickle', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변수 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name+'_variable.json') as f:\n",
    "    var = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불용어 단어 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name+'_stopwords.json') as f:\n",
    "    stopwords = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불러온 변수 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_data: 10\n",
      "data_length: 100\n",
      "max_len: 100\n",
      "trunc_type: post\n",
      "padding_type: post\n"
     ]
    }
   ],
   "source": [
    "min_data = var['min_data'] # 데이터 문자열 최소 길이\n",
    "data_length = var['data_length'] # 데이터 문자열 최대 길이\n",
    "split_list = var['split_list'] # 문장 단위로 분리하기 위한 글자 리스트\n",
    "max_len = var['max_len'] # 전체 데이터 셋 길이 설정 (메일의 최대 길이)\n",
    "trunc_type = var['trunc_type']\n",
    "padding_type = var['padding_type']\n",
    "\n",
    "print('min_data:',min_data)\n",
    "print('data_length:',data_length)\n",
    "print('max_len:',max_len)\n",
    "print('trunc_type:',trunc_type)\n",
    "print('padding_type:',padding_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STT 변환\n",
    "\n",
    "음성파일 STT변환\n",
    "* `language`: 언어 설정\n",
    "* 약 80~100MB 용량 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "audio_file = [\"spam1.wav\", \"spam2.wav\"]\n",
    "\n",
    "stt_list = []\n",
    "for a in audio_file:\n",
    "    r = sr.Recognizer()\n",
    "    harvard = sr.AudioFile(a) # 100MB 용량 제한\n",
    "    with harvard as source:\n",
    "        audio = r.record(source)\n",
    "\n",
    "    try:\n",
    "        t = r.recognize_google(audio, language='ko-KR')\n",
    "    except:\n",
    "        t = '녹음 내용이 존재하지 않습니다.'\n",
    "        \n",
    "    stt_list.append(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텍스트 데이터 분리\n",
    "\n",
    "**findIndex**: 문장이 끝나는 부분의 index값을 찾기위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findIndex(data_list, split_list, start_index):\n",
    "    index_list = []\n",
    "    for i in split_list:\n",
    "        index = data_list.find(i, start_index)\n",
    "        index_list.append(index)\n",
    "        \n",
    "    index_list = [i for i in index_list if i not in [-1]]\n",
    "    if index_list == []:\n",
    "        return -1\n",
    "    \n",
    "    index = min(index_list)\n",
    "    \n",
    "    return index     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data_length` 값 이후에 `split_list` 에 있는 문자가 나오면 자르기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for t in stt_list:\n",
    "    t = re.sub(\"네|[^가-힣 ]\", \"\", t) # 특수문자 제거\n",
    "    index = findIndex(t, split_list, data_length)\n",
    "\n",
    "    i = 0\n",
    "    t_list = []\n",
    "    while index != -1:\n",
    "        x = t[i:index+2]\n",
    "        t_list.append(x)\n",
    "\n",
    "        i = index+2\n",
    "        index = findIndex(t, split_list, i+data_length)\n",
    "    else:\n",
    "        x = t[i:]\n",
    "        if len(x) > min_data:\n",
    "            t_list.append(x) # 텍스트 마지막 부분 추가\n",
    "            \n",
    "    result.append(t_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전처리: 토큰화 및 불용어 처리\n",
    "\n",
    "Okt 객체 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**preTreatment**: 토큰화 및 불용어 처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preTreatment(data):\n",
    "    global stopwords\n",
    "    temp = okt.morphs(data, stem=True) # 토큰화\n",
    "    temp = [word for word in temp if not word in stopwords] # 불용어 처리\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**sentiment_predict**: 정수 인코딩 후 모델 예측 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_predict(new_sentence):\n",
    "    data = tokenizer.texts_to_sequences([new_sentence])\n",
    "    pad_new = pad_sequences(data, maxlen = max_len, truncating = trunc_type, padding = padding_type)\n",
    "    score = float(model.predict(pad_new))\n",
    "#     print(score)\n",
    "#     print('----------------------')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 예측\n",
    "\n",
    "학습된 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 100)         657100    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, None, 128)         117248    \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, None, 128)         131584    \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,037,645\n",
      "Trainable params: 1,037,645\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(file_name+'.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분리한 각 데이터 확률 예측 후 평균 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여보세요 여보세요 여기 서울중앙지검 잠시 통화 괜찮으십니까 다름이 아니라 본인 명의도용사건 관련해서 몇 가지 사실 확인 차 연락 드렸어요 저는 서울중앙지검 특별수사팀 제일 보강은 영숙아이라고 합니다 \n",
      "예 부모님께서 대구 달서구 출신인    감동이라는 사람 아는 사람이십니까 최고야 최관동이라고 합니다 최관동 처음 들어 보는데 그 대구 달서구 출신이구요   되고 저기 그 농협은행 직원이었습니다 \n",
      "전혀 모르는 사람 맞으신가요 예 알겠습니다 제가 그 사람에 대해서 외제차 여쭤봐야 만요 저희 수사팀에서 이번에 대구 달서구에서 발생한 금융사기를 조사하던중 안동을 중심으로 일정 대로 검거했습니다 \n",
      "하다 보니까 신분증 신용카드도 했었는데요 농협 은행 통장 발급 돼서 연락을 드린 거고요 혹시 통장에 대해서 알고 있는 내용 있습니까 아니요 전혀 없는데요 어떻게 해야 되나요 알겠습니다 \n",
      "대해서 저희 측에 더 확인이 잘 부분이고요 년 월 일 목요일 있고요 달서구 대덕 지점에서 발급 된 걸로 확인이 되거든요 어머님께서 발급받은 통장들이 왔습니까 어디서 농협은행과 신한은행 같은 경우 통장 별들이 년 월 일 목요일 이고요 \n",
      "대구 달서구 대덕 지점에서 발급이 된 걸로 확인이 되거든요 아니요 거기서 저녁 대구 달서구 따로 연구실에 없으신 거 맞으시고요 알겠습니다 화장실 방법은에 대해서 제가 지금 현재 연락을 드렸는데요 \n",
      "친구 단말기에  연락을 드린 거고요 내선번호로 연락드리면 발급시스템 폰으로 오셔서 안 받는 경우가 많더라고요 그렇기 때문에 해당 부분을 저희가 녹취는 단말기로 연락을 드린 거고요 분위기에서 좀 양해를 해 주셔야 하는데 일단 조사를 하고 있는데요 \n",
      "현 시점에서 사건 현장과 용이점 묵호에서 본인명의 천상두 저 발견되었기 때문에 저희 쪽에서는 본인이 통장을 판매할 수 있는지 아니면 개인정보 유출로 인한 피해 사실을 있는지 그 부분에 대해서 조사를 하고 있는 중이고요 \n",
      "무엇보다도 중요한 점이 통장이 사용됨으로써 다수의 피해자와의 성장하는 피해 금요일까지 발생을 했기 때문에 되지 않도록이 통장은 본인이 발급받은 송장이 아니다라고 생각하시면 기본적인 진출이 필요한 부분이고요 \n",
      "선택은 저희 가까이 교류가 되어있는데요 대해서 일일이 소환조사가 어렵기 때문에 일차적인 혐의점이 없으신 분 위주로 내가 약식조사 진행을 하는 겁니다 해당 부분에 대해서 본인 같은 경우도 혐의점이 없으시기 때문에 녹취조사로 진행을 할 거고요 \n",
      "녹취본 같은 경우 본인을 대신에 법원의 증거자료로 채팅을 할 것이기 때문에 욕실 중에 거짓진술 하시거나 내용에 대해서 본인에게 불리하게 적용될 수 있고요 주님께서 전화 받으시는 공간이 어떻게 되시나요 \n",
      "어디서 전화하고 있냐고요 전화 받으시는 공간이야 사무실에 있는데 알겠습니다 그 해당 부분에 대해서 저희가 녹취 중에는 주위에 잡음이나 타인의 원숭이 중독되기 되면 증거자료로 혜택이 되지 않기 때문에 질문 드린 거고요 \n",
      "지금 지금 해야 되나요 그러면 그 저희가 해당 부분에 대해서는 본인께서 나오신 없어서 받으시거나 두 가지로 진행이 되고요 주님께서 나오셔서 주사 맞은 쉬겠다 하라고 하면 제가 소환일정 소환장 발 보내 드릴 겁니다 \n",
      "예 녹취 해도 되는데요 지금 저 잠깐 누가 있어 가지고 그러면은 조용한 곳에서 해야 된다 하셔가지고 그럼 조금 있다 해도 되나요 혹시 그 제가 해당 부분에 대해서 본인 맞춰서 하는 부분이 아니라서요 \n",
      "혹시 그러면 해당 부분에 대해서 몇 시쯤에 통화 괜찮으세요 한 시 한 분 뒤에는 괜찮아 아 분 알겠습니다 제가 확인하고 그럼 다시 연락 드리도록 하겠습니다이 번호로 다시 전화 주시는 건가요이 번호로 연락 드리도록 하겠습니다 \n",
      "74.08% 확률로 스팸입니다.\n",
      "\n",
      "안녕하세요 혹시 대구 달서구 이거 지금 안성 노란사람 알고 계세요 뭐라고요 안성모 모르는데요 천지농협 아니고요 살 안성 신데 김현진 알송에서 들어보신적이 없으시고요 아 그러세요 저희가 이번에 안성 모드 중심으로 금융범죄 사귀자는 한번 했는데 대포통장대여 위조신분증 거기에 신한은행 하고 농협 통장에 같이 발급이 되어 있었어요 \n",
      "통장에 대해서 아시는 없으시고요 제가 생각한 적이 없는데 아 그래서 지금 농협은 쉬세요 농협은 옛날에 옛날에 아 그냥 그게 이제 년 월 일 대구 달서구에서 발급이 되었는데 그 본인이 발급받으시고 맞으세요 \n",
      "제가 오늘 보긴 앞으로 연락을 지금 이유가 영해 통장이 대포통장으로 개설되었고 그래서 피해사실확인서 드렸고요 범죄 사용해 여자들이 발생이 대부분인데요 저희 쪽에서 전반적인 내용을 결과 경우에는 확실하기 때문에 일이 있어서 연락을 드렸습니다 \n",
      "본인 명의의 통장에 발견되었다고 해서 저희가 무조건 가해자로 모든게 아니라 어느 정도는 피해자라고 보고 있습니다 잠을 아직까지 피해자라고 증명을 증거 계시기 때문에 피해 입증 조사를 도와드리면 부분이고요 \n",
      "없으시기 때문에 저희들이 약식으로 녹취 조사를 진행을 할 거고요 치료사가 본인을 대신에 법원에 제출할 중요한 서류가 되기 때문에 주위에 작업이나 제 자에 목소리 섞이면 실적이 안 됩니다 \n",
      "주시기 바라겠습니다 아시겠죠 녹슬은 되게 중요한 보고 말씀드리겠습니다 드릴게요 제일 중요한 부분은요 본인 개인정보법 의해서 주민번호 계좌번호 비밀번호 절대로 말씀하시면 안 되시고요 질문에 아신다 \n",
      "모르신다 간단하게 진실을 주시면 되세요 그럼 제가 욕실전등 해도 되겠습니까 지금 운전 중이신가 봐요 운전 중 통화 괜찮으세요 건데 아 알겠습니다 문자 주시고 그럼 제가 지금 바로 시작하겠습니다 \n",
      "안녕하십니까 저는 서울중앙지검 신입사원입니다 욕심으로 담을 수 있게 본인 성함과 나이를 친추해주세요 거라고요 심혜수 아이예요 서울중앙지검이 어딘데 수원에 있어요 서초동 대구지방검찰청 이사 잘 하고 거기서 없어요 \n",
      "자기가 날인데요 그 사람은 사람인데 저희가 날이에요 그럼 제가 가지고 문자로 발송해 드릴게요 그거 이제 받아 보시고 나오셔서 상담받으시면 되세요\n",
      "72.61% 확률로 스팸입니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t_list in result:\n",
    "    score_sum = 0.0\n",
    "    \n",
    "    for txt in t_list:\n",
    "        print(txt)\n",
    "        data = preTreatment(txt)\n",
    "        score_sum += sentiment_predict(data)\n",
    "\n",
    "    score_result = score_sum / len(t_list)\n",
    "    \n",
    "    print(\"{:.2f}% 확률로 스팸입니다.\\n\".format(score_result * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예측 확률 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(\"{:.2f}% 확률로 스팸입니다.\\n\".format(score_result * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
